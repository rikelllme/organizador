import streamlit as st
from api_client import get_projetos
from chatbot import create_llm, make_prompt

st.set_page_config(page_title="Chat de Projetos", layout="wide")
st.title(" Chat de Projetos com LLM (Streaming)")

# Inicializa hist贸rico
if "history" not in st.session_state:
    st.session_state.history = []

# Carrega dados da API (uma vez)
if "dados_api" not in st.session_state:
    st.session_state.dados_api = get_projetos()

# Mostra dados da API em painel expans铆vel
with st.expander(" Dados carregados da API"):
    st.json(st.session_state.dados_api)

# Exibe hist贸rico de conversa
for msg in st.session_state.history:
    st.chat_message(msg["role"]).markdown(msg["content"])

# Entrada do usu谩rio
if prompt := st.chat_input("Digite sua pergunta..."):
    # Adiciona pergunta ao hist贸rico
    st.session_state.history.append({"role": "user", "content": prompt})
    st.chat_message("user").markdown(prompt)

    # Cria LLM e prompt
    llm = create_llm()
    contexto = make_prompt(st.session_state.dados_api, prompt)

    # Cria bolha de resposta vazia
    message_placeholder = st.chat_message("assistant")
    resposta_texto = ""

    # Streaming da resposta
    for token in llm.stream(contexto):
        resposta_texto += token
        message_placeholder.markdown(resposta_texto)

    # Salva no hist贸rico
    st.session_state.history.append({"role": "assistant", "content": resposta_texto})
